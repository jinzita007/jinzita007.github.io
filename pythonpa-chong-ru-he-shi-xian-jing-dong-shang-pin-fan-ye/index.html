

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <link href="../assets/css/main.css?v=5e892d17e0" rel="stylesheet" type="text/css">
    <link rel="stylesheet" type="text/css" href="../assets/css/screen.css?v=5e892d17e0">
    <link rel="stylesheet" href="https://highlightjs.org/static/demo/styles/github.css">
    <script src="https://cdn.bootcss.com/highlight.js/9.15.6/highlight.min.js"></script>
    

    <title></title>
     <link rel="shortcut icon" href="../favicon.ico" type="image/x-icon">
    <link rel="canonical" href="index.html">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <link rel="amphtml" href="amp/index.html">
    
    <meta property="og:site_name" content="无根树の博客">
    <meta property="og:type" content="article">
    <meta property="og:title" content="Python爬虫如何实现京东商品翻页">
    <meta property="og:description" content="上次我讲解关于一篇Python爬虫京东商品列表的文章，大家都知道了。我现在本篇主要讲解关于如何爬虫实现翻页的文章。我希望本文也许能帮助你们。 先把京东网址的翻页有多少，就可以遍历商品列表 抓取翻页的最大数量 turnPageBottom = soup.find(&amp;quot;a&amp;quot;,{&amp;quot;id&amp;quot;: &amp;quot;lastPage&amp;quot;}).string #抓取翻页的最大数量 for循环常与range函数一起使用 for index in range(int(turnPageBottom)):     print(index+1) 输出结果 1 2 . . 47 48 49 50 然后用加上就是p=str(index+1),就可以遍历获取翻页的网址 for index in range(int(turnPageBottom)):     urlpage">
    <meta property="og:url" content="http://localhost:2368/pythonpa-chong-ru-he-shi-xian-jing-dong-shang-pin-fan-ye/">
    <meta property="article:published_time" content="2018-02-05T08:20:36.000Z">
    <meta property="article:modified_time" content="2018-02-05T08:00:30.000Z">
    <meta property="article:tag" content="python">
    <meta property="article:tag" content="爬虫">
    <meta property="article:tag" content="beautifulsoup">
    
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Python爬虫如何实现京东商品翻页">
    <meta name="twitter:description" content="我现在本篇主要讲解关于如何爬虫实现翻页的文章。">
    <meta name="twitter:url" content="http://localhost:2368/pythonpa-chong-ru-he-shi-xian-jing-dong-shang-pin-fan-ye/">
    <meta name="twitter:label2" content="Filed under">
    <meta name="twitter:data2" content="python, 爬虫, beautifulsoup">
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "无根树の博客",
        "logo": {
            "@type": "ImageObject",
            "url": "http://localhost:2368/favicon.ico",
            "width": 60,
            "height": 60
        }
    },
    "author": {
        "@type": "Person",
        "name": "",
        "url": "http://localhost:2368/author/",
        "sameAs": []
    },
    "headline": "Python爬虫如何实现京东商品翻页",
    "url": "http://localhost:2368/pythonpa-chong-ru-he-shi-xian-jing-dong-shang-pin-fan-ye/",
    "datePublished": "2018-02-05T08:20:36.000Z",
    "dateModified": "2018-02-05T08:00:30.000Z",
    "keywords": "python, 爬虫, beautifulsoup",
    "description": "上次我讲解关于一篇Python爬虫京东商品列表的文章，大家都知道了。我现在本篇主要讲解关于如何爬虫实现翻页的文章。我希望本文也许能帮助你们。 先把京东网址的翻页有多少，就可以遍历商品列表 抓取翻页的最大数量 turnPageBottom &#x3D; soup.find(&amp;quot;a&amp;quot;,{&amp;quot;id&amp;quot;: &amp;quot;lastPage&amp;quot;}).string #抓取翻页的最大数量 for循环常与range函数一起使用 for index in range(int(turnPageBottom)):     print(index+1) 输出结果 1 2 . . 47 48 49 50 然后用加上就是p&#x3D;str(index+1),就可以遍历获取翻页的网址 for index in range(int(turnPageBottom)):     urlpage",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "http://localhost:2368/"
    }
}
    </script>

    <script type="text/javascript" src="../public/ghost-sdk.min.js?v=5e892d17e0"></script>
<script type="text/javascript">
ghost.init({
	clientId: "ghost-frontend",
	clientSecret: "a41d73990106"
});
</script>
    <meta name="generator" content="Ghost 1.20">
    <link rel="alternate" type="application/rss+xml" title="无根树の博客" href="../rss/index.html">
</head>

<body class="post-template tag-python tag-pa-chong tag-beautifulsoup">

    
 <div class="header">
    <div class="header-inder">
        <nav class="site-navs">
            <div class="site-nav-left">
                <a class="site-nav-logo" href="../">无根树の博客</a>
                  <ul class="nav" role="menu">
    <li class="nav-" role="menuitem"><a href="https://jinzita007.github.io">首页</a></li>
    <li class="nav-" role="menuitem"><a href="https://jinzita007.github.io/records">归档</a></li>
    <li class="nav-" role="menuitem"><a href="https://jinzita007.github.io/tags">标签</a></li>
    <li class="nav-github" role="menuitem"><a href="https://github.com/jinzita007">github</a></li>
</ul>
 
            </div>
            <div class="site-nav-right">
                <form class="form-inline my-2 my-lg-0">
                    <input id="search-field" class="form-control mr-sm-2" type="text" placeholder="Search">
                    <!--<button class="btn btn-secondary my-2 my-sm-0" type="submit">搜索</button>-->
                </form>
            </div>

        </nav>
    </div>
</div>
<section id="results-main">
    <ul id="results" class="results-search">
    </ul>
</section>
    <div class="container">
        <div class="wrap">
            <div class="content-main">
                 
                <div class="content-title">
                    <h1>Python爬虫如何实现京东商品翻页</h1>
                    <span class="post-main">
                        <span class="post-time">
                            <span class="post-meta-item-icon">
                                <i class="fa fa-calendar-o"></i>
                            </span>
                            <time class="post-meta-time">2018-02-05</time>
                        </span>  |   
                        <span class="tags">
                             <a href="../tag/python/">python</a> <a href="../tag/pa-chong/">爬虫</a> <a href="../tag/beautifulsoup/">beautifulsoup</a>
                        </span>
                    </span>
                </div>
                <div class="content-dec">
                    
                    <div class="kg-card-markdown"><blockquote>
<p>上次我讲解关于一篇Python爬虫京东商品列表的文章，大家都知道了。我现在本篇主要讲解关于如何爬虫实现翻页的文章。我希望本文也许能帮助你们。</p>
</blockquote>
<blockquote>
<p>先把京东网址的翻页有多少，就可以遍历商品列表</p>
</blockquote>
<p><img src="../content/images/2018/02/Snipaste_2018-02-05_16-07-09.png" alt="Snipaste_2018-02-05_16-07-09"></p>
<blockquote>
<p>抓取翻页的最大数量</p>
</blockquote>
<pre><code>turnPageBottom = soup.find("a",{"id": "lastPage"}).string #抓取翻页的最大数量
</code></pre>
<blockquote>
<p>for循环常与range函数一起使用</p>
</blockquote>
<pre><code>for index in range(int(turnPageBottom)):
    print(index+1)
</code></pre>
<blockquote>
<p>输出结果</p>
</blockquote>
<pre><code>1
2
.
.
47
48
49
50
</code></pre>
<blockquote>
<p>然后用加上就是p=str(index+1),就可以遍历获取翻页的网址</p>
</blockquote>
<pre><code>for index in range(int(turnPageBottom)):
    urlpage = "http://search.yhd.com/c0-0-1003817/mbname-b/a-s1-v4-p"
    page = urlpage + str(index+1) + "-price-d0-f0-m1-rt0-pid-mid0-color-size-k/"
    print(page)
</code></pre>
<blockquote>
<p>输出结果</p>
</blockquote>
<pre><code>http://search.yhd.com/c0-0-1003817/mbname-b/a-s1-v4-p1-price-d0-f0-m1-rt0-pid-mid0-color-size-k/
http://search.yhd.com/c0-0-1003817/mbname-b/a-s1-v4-p2-price-d0-f0-m1-rt0-pid-mid0-color-size-k/
...
http://search.yhd.com/c0-0-1003817/mbname-b/a-s1-v4-p50-price-d0-f0-m1-rt0-pid-mid0-color-size-k/
</code></pre>
<blockquote>
<p>现在我们写的完整项目</p>
</blockquote>
<pre><code># -*- coding: utf-8 -*-
#---------------------------------------
#   程序：商品爬虫
#   版本：0.0.1
#   作者：woaitianwen
#   日期：2018-2-3
#   语言：Python 3.6
#   操作：输入网址后就获取商品列表，然后存到mysql数据库
#---------------------------------------


from urllib.request import urlopen
from bs4 import BeautifulSoup
import re
import mysql.connector

#连接mysql数据库
conn = mysql.connector.connect(user='root', password='root', database='mynode')
#使用cursor()方法获取操作游标
cur = conn.cursor()

url = "http://search.yhd.com/c0-0-1003817/mbname-b/a-s1-v4-p1-price-d0-f0-m1-rt0-pid-mid0-color-size-k/?ref=ad.21102_47515303_1#page=2&amp;sort=1";
html = urlopen(url)  #请求网址
soup = BeautifulSoup(html, "lxml")  #解析网页信息

proPrice = soup.select("p.proPrice em")  #抓取价格
pdlink2 = soup.select('p.proName &gt; a')   #抓取商品名称

turnPageBottom = soup.find("a",{"id": "lastPage"}).string #抓取翻页的最大数量

for index in range(int(turnPageBottom)):
    #print(index+1)
    urlpage = "http://search.yhd.com/c0-0-1003817/mbname-b/a-s1-v4-p"
    page = urlpage + str(index+1) + "-price-d0-f0-m1-rt0-pid-mid0-color-size-k/"
    #print(page)
    html = urlopen(page)  # 请求网址
    soup = BeautifulSoup(html, "lxml")  # 解析网页信息

    proPrice = soup.select("p.proPrice em")  # 抓取价格
    pdlink2 = soup.select('p.proName &gt; a')  # 抓取商品名称

    for title,price in zip(pdlink2,proPrice):
        data = [] # 建一个列表，用于存放数据
        try:
            title = title.contents[-1]     #将列表中的每一个商品信息提取出来
            price = price.contents[-1]   #将列表中的每一个商品价格提取出来
            # 正则表达式
            dr = re.compile(r'\n|',re.S)
            # 正则的替换
            dd_title = dr.sub('', title)
            dd_price = dr.sub('', price)
            # 移除空格
            dd_s_title = dd_title.strip()
            dd_s_price = dd_price.strip()

            #print("[*] 商品标题:", title)  #输出商品标题
            #print("[*] 商品价格:", price) #输出商品价格

            data.append([dd_s_title,dd_s_price]) ##将爬取的数据依次填入列表中

            print(data)
            sql = "INSERT INTO goods (title,price) values(%s,%s)"  # 这是一条sql插入语句
            cur.executemany(sql, data)  # 执行sql语句，并用executemany()函数批量插入数据库中
            conn.commit()
        except Exception as e:
            print(e)
            conn.rollback()


# 释放数据连接
if cur:
    cur.close()
if conn:
    conn.close()
</code></pre>
<blockquote>
<p>我不再重复讲解具体的内容，大家都可以去看看我上次讲解关于：<a href="https://www.yulong360.com/pythonpa-chong-jing-dong-shang-pin-lie-biao-2/">《Python爬虫京东商品列表》</a></p>
</blockquote>
</div>
                </div>

            </div>
        </div>
    </div>

    <script>
   
    </script> 


</body>
<script src="https://cdn.bootcss.com/jquery/2.2.0/jquery.min.js"></script>
<script src="../assets/js/jquery.ghostHunter.js?v=5e892d17e0" type="text/javascript"></script>
<script>

    //实时监听input框输入值并增加搜索
    var input = document.getElementById('search-field');
    $("#search-field").ghostHunter({
        results: "#results",
        onKeyUp: true,
        displaySearchInfo: false,
        before: function () {
            input.oninput = function () {
                //如果输入值为空时，列表内容就显示出来
                if (input.value === '') {
                    //console.log(input.value);
                    $(".wrap-active").removeClass("results-hide");
                } else {
                    //如果输入值为有字符，列表内容就隐藏
                    //console.log(input.value);
                    $(".wrap-active").addClass("results-hide");
                }
            }
        }
    });

</script>
<script>hljs.initHighlightingOnLoad();</script>


